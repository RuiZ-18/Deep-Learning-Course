{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 内容一：在MNIST数据集上构建网络进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 实验前导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as tud\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学会使用Dataloader来加载数据\n",
    "Dataloader能够帮我们打乱数据集，拿到batch数据 \\\n",
    "为了使用Dataloader，需要定义以下三个function\n",
    "- \\__init__: 模型初始化\n",
    "- \\__len__: 返回整个数据集有多少item\n",
    "- \\__getitem__: 根据给定的index返回一个item\n",
    "\n",
    "调用Dataloader之前还要先定义dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch帮助我们预先加载了一些常用的数据集\n",
    "# 如果使用这些数据集，会相对容易的进行数据加载\n",
    "# 例如：常用的Mnist数据集\n",
    "mnist_train_data = datasets.MNIST(\"./mnist_data\",train=True,download=True,\n",
    "                                 transform = transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=(0.13066062,),std=(0.30810776,))\n",
    "                                 ]))\n",
    "batch_size = 64\n",
    "train_dataloader = tud.DataLoader(mnist_train_data,batch_size = batch_size,shuffle=True) # 将dataset转换为iterator\n",
    "mnist_test_data = datasets.MNIST(\"./mnist_data\",train=False,download=True,\n",
    "                                 transform = transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=(0.13066062,),std=(0.30810776,))\n",
    "                                 ]))\n",
    "test_dataloader = tud.DataLoader(mnist_test_data,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = datasets.MNIST(\"./mnist_data\",train=True,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iuj8I+ELjxVNfP8AaUs9P0+3a4vLtxuESgEgBcjJJGOvrXOUqI0jqiKWdjhVAySfSvYYvh7rnhj4Wao02hzXmr608MXkRIJHs4VbcGYDkMzcYHtnpisnxd5PgXwVD4HhlWXV7yRb3V5Y2I8r5Rsg9+OTn64548zq9o+rXehatb6nYsi3VuS0TOgYK2CAcHjIzke4FeoeFfEup+FfCWq+OtS1We61PVi1lp8Mkxfe69ZXHIwnZSP0IrznxJ4o1fxbqY1DWrr7RcrGI1YIqAKMnACgDuax6KKKK//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5ElEQVR4AWNgGDRg7z6QU5iwuqff6jZWcZBgx/dPYTglD/zZjSlnt1MIJBj55qY+puSNvzYgwSv/AyFyKA769p8DKGog9w9EoYHm31dEGRi4l/85yoomw8Ag++K7PVBw5p9HGFIMurf/9ANFS37+SUeXZEn4+//viSp2yZO/5qHLMcT8+fP35p8/Jx7/eY4hF/77+3NHg71AFX9+P1ZGk953NwkoonUEKPlnEZocQ74sSMTu/Z8wLS0+dEkwn3/K31tYJUCClX+ey+CSlL/7uxGXHMOtPwvQ5JACfgHDJjTJgeACAIV4U3HXHMRJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data[9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = datasets.MNIST(\"./mnist_data\", train=True, download=True,\n",
    "                           transform = transforms.Compose([\n",
    "                               transforms.ToTensor()\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7412, 0.7451,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5608, 0.9686, 0.6000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9686, 0.9490, 0.3373,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.7529, 0.9882, 0.7333, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.7255, 0.0706, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.3490, 0.9255, 0.8510, 0.1843, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.8471, 0.9922, 0.2353, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.8314, 1.0000, 0.3176, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.8078, 0.9882, 0.2667, 0.0000,\n",
       "          0.0000, 0.0000, 0.1882, 0.9490, 0.9922, 0.3490, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5137, 0.9843, 0.8314, 0.0824, 0.0000,\n",
       "          0.0000, 0.0431, 0.6549, 0.9882, 0.7725, 0.0196, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.1137, 0.9098, 0.9686, 0.2471, 0.0000, 0.0000,\n",
       "          0.0000, 0.6000, 0.9882, 0.8863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.1765, 0.8588, 0.9882, 0.5608, 0.0000, 0.0000, 0.0000,\n",
       "          0.4549, 0.9765, 0.9882, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157,\n",
       "          0.3765, 0.9922, 1.0000, 0.9922, 0.7843, 0.4784, 0.0275, 0.0980,\n",
       "          0.7882, 0.9804, 0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3608,\n",
       "          0.9882, 0.9882, 0.9922, 0.8510, 0.9882, 0.9882, 0.7843, 0.8902,\n",
       "          0.9882, 0.9059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.9843,\n",
       "          0.9686, 0.9059, 0.2549, 0.1882, 0.7412, 0.9882, 0.9882, 0.9922,\n",
       "          0.9882, 0.9843, 0.8902, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7451, 0.8667,\n",
       "          0.3843, 0.0000, 0.0000, 0.0000, 0.1647, 0.7686, 0.9882, 0.9922,\n",
       "          0.9882, 0.9882, 0.6353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.1137,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.9373, 0.9882, 0.3373,\n",
       "          0.1647, 0.1647, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0588, 0.5804, 0.9922, 0.8549, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.4745, 0.9882, 0.9059, 0.1098, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.1216, 0.8667, 0.9843, 0.5059, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.8549, 0.9882, 0.6275, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.4784, 0.9882, 0.3216, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data[9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30810776"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [d[0].data.numpy() for d in mnist_data]\n",
    "np.std(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 配置网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 定义网络\n",
    "- 继承 nn.Module\n",
    "- 初始化函数\n",
    "- forward 函数\n",
    "- 其余可以根据模型需要定义相关的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个简单的基于ConvNet的简单神经网络\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__() # the input is 1*28*28\n",
    "        self.conv1 = nn.Conv2d(1,20,5,1) # (28-5)/1+1=24, 20*24*24\n",
    "        self.conv2 = nn.Conv2d(20,50,5,1) # 12-5+1=8\n",
    "        self.fc1 = nn.Linear(4*4*50,500)\n",
    "        self.fc2 = nn.Linear(500,10)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x)) # 20 * 24 * 24\n",
    "        x = F.max_pool2d(x,2,2) # 20 * 12 * 12\n",
    "        x = F.relu(self.conv2(x)) # 50 * 8 * 8\n",
    "        x = F.max_pool2d(x,2,2) # 50 * 4 * 4\n",
    "        x = x.view(-1,4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x #F.log_softmax(x,dim=1)\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "optimizer = optim.SGD(model.parameters(),lr=lr,momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型一般需要训练若干个epoch\n",
    "- 每个epoch我们把所有数据分成若干个batch\n",
    "- 把每个batch的输入和输出都包装成cuda Tensor\n",
    "- forward pass\n",
    "- 计算loss\n",
    "- 清空gradient\n",
    "- backward pass\n",
    "- 更新模型参数\n",
    "- 每隔一定的iteration输出loss，以及在验证集上做模型的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_dataloader,loss_fn,optimizer,epoch):\n",
    "    model.train()\n",
    "    for idx, (data, label) in enumerate(train_dataloader):\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output,label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx % 100 == 0:\n",
    "            print(\"Train Epoch: {}, iteration: {}, loss: {}\".format(\n",
    "                epoch,idx,loss.item()))  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_dataloader,loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    correct = 0.\n",
    "    with torch.no_grad():\n",
    "        for idx, (data,target) in enumerate(test_dataloader):\n",
    "            output = model(data) # batch_size * 10        \n",
    "            loss = loss_fn(output,target)*output.size(0)\n",
    "            pred = output.argmax(dim=1)\n",
    "            total_loss += loss\n",
    "            correct += pred.eq(target).sum()\n",
    "    total_loss /= len(test_dataloader.dataset)\n",
    "    acc = correct/len(test_dataloader.dataset)\n",
    "    print(\"Test Loss:{}, Accuracy:{}\".format(total_loss,acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, iteration: 0, loss: 2.3114867210388184\n",
      "Train Epoch: 0, iteration: 100, loss: 0.8056374788284302\n",
      "Train Epoch: 0, iteration: 200, loss: 0.3295554220676422\n",
      "Train Epoch: 0, iteration: 300, loss: 0.14907078444957733\n",
      "Train Epoch: 0, iteration: 400, loss: 0.3567638099193573\n",
      "Train Epoch: 0, iteration: 500, loss: 0.31864452362060547\n",
      "Train Epoch: 0, iteration: 600, loss: 0.13163012266159058\n",
      "Train Epoch: 0, iteration: 700, loss: 0.06611235439777374\n",
      "Train Epoch: 0, iteration: 800, loss: 0.04001199081540108\n",
      "Train Epoch: 0, iteration: 900, loss: 0.18037915229797363\n",
      "Test Loss:0.09847679734230042, Accuracy:0.9710999727249146\n",
      "Train Epoch: 1, iteration: 0, loss: 0.11229132860898972\n",
      "Train Epoch: 1, iteration: 100, loss: 0.06748390942811966\n",
      "Train Epoch: 1, iteration: 200, loss: 0.038600947707891464\n",
      "Train Epoch: 1, iteration: 300, loss: 0.04738940671086311\n",
      "Train Epoch: 1, iteration: 400, loss: 0.0798511803150177\n",
      "Train Epoch: 1, iteration: 500, loss: 0.019416717812418938\n",
      "Train Epoch: 1, iteration: 600, loss: 0.07917514443397522\n",
      "Train Epoch: 1, iteration: 700, loss: 0.030751770362257957\n",
      "Train Epoch: 1, iteration: 800, loss: 0.20703722536563873\n",
      "Train Epoch: 1, iteration: 900, loss: 0.07227848470211029\n",
      "Test Loss:0.05717659741640091, Accuracy:0.9818000197410583\n"
     ]
    }
   ],
   "source": [
    "#torch.save(model.state_dict(),\"mnist_cnn.pth\")\n",
    "num_epochs = 2\n",
    "best_valid_acc = 0.\n",
    "for epoch in range(num_epochs):\n",
    "    train(model,train_dataloader,loss_fn,optimizer,epoch)\n",
    "    acc = test(model,test_dataloader,loss_fn)\n",
    "    if acc > best_valid_acc:\n",
    "        best_valid_acc = acc\n",
    "        torch.save(model.state_dict(),\"best_mnist_cnn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.05717659741640091, Accuracy:0.9818000197410583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9818)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = Net()\n",
    "test_model.load_state_dict(torch.load(\"best_mnist_cnn.pth\"))\n",
    "test(model,test_dataloader,loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FashionMNIST数据集\n",
    "mnist_train_data = datasets.FashionMNIST(\"./fashion_mnist_data\",train=True,download=True,\n",
    "                                 transform = transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=(0.13066062,),std=(0.30810776,))\n",
    "                                 ]))\n",
    "batch_size = 64\n",
    "train_dataloader = tud.DataLoader(mnist_train_data,batch_size = batch_size,shuffle=True) # 将dataset转换为iterator\n",
    "mnist_test_data = datasets.FashionMNIST(\"./fashion_mnist_data\",train=False,download=True,\n",
    "                                 transform = transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=(0.13066062,),std=(0.30810776,))\n",
    "                                 ]))\n",
    "test_dataloader = tud.DataLoader(mnist_test_data,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, iteration: 0, loss: 2.328911781311035\n",
      "Train Epoch: 0, iteration: 100, loss: 0.9987826347351074\n",
      "Train Epoch: 0, iteration: 200, loss: 0.7665319442749023\n",
      "Train Epoch: 0, iteration: 300, loss: 0.8882497549057007\n",
      "Train Epoch: 0, iteration: 400, loss: 0.7011545300483704\n",
      "Train Epoch: 0, iteration: 500, loss: 0.5955065488815308\n",
      "Train Epoch: 0, iteration: 600, loss: 0.932137131690979\n",
      "Train Epoch: 0, iteration: 700, loss: 0.5328547358512878\n",
      "Train Epoch: 0, iteration: 800, loss: 0.5334343910217285\n",
      "Train Epoch: 0, iteration: 900, loss: 0.6081203818321228\n",
      "Test Loss:0.5485048294067383, Accuracy:0.7797999978065491\n",
      "Train Epoch: 1, iteration: 0, loss: 0.5807403922080994\n",
      "Train Epoch: 1, iteration: 100, loss: 0.4633340835571289\n",
      "Train Epoch: 1, iteration: 200, loss: 0.5963548421859741\n",
      "Train Epoch: 1, iteration: 300, loss: 0.4349920153617859\n",
      "Train Epoch: 1, iteration: 400, loss: 0.4948941171169281\n",
      "Train Epoch: 1, iteration: 500, loss: 0.6521319150924683\n",
      "Train Epoch: 1, iteration: 600, loss: 0.42003190517425537\n",
      "Train Epoch: 1, iteration: 700, loss: 0.5193905234336853\n",
      "Train Epoch: 1, iteration: 800, loss: 0.27609947323799133\n",
      "Train Epoch: 1, iteration: 900, loss: 0.36373069882392883\n",
      "Test Loss:0.4483276903629303, Accuracy:0.8428000211715698\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "optimizer = optim.SGD(model.parameters(),lr=lr,momentum=momentum)\n",
    "num_epochs = 2\n",
    "best_valid_acc = 0.\n",
    "for epoch in range(num_epochs):\n",
    "    train(model,train_dataloader,loss_fn,optimizer,epoch)\n",
    "    acc = test(model,test_dataloader,loss_fn)\n",
    "    if acc > best_valid_acc:\n",
    "        best_valid_acc = acc\n",
    "        torch.save(model.state_dict(),\"best_fashion_mnist_cnn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 内容二：CNN模型的迁移学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 很多时候当我们训练一个新的图像分类任务，我们不会完全从一个随机的模型开始训练，而是利用预训练的模型来加速训练的过程。我们经常使用在ImageNet上的预训练模型\n",
    "- 有两种方法做迁移学习\n",
    "    - finetuning：从一个预训练模型开始，改变一些模型的架构，然后继续训练整个模型的参数；\n",
    "    - feature extraction：不改变预训练模型的参数，只更新我们改变过的部分模型参数。（当成特征提取器来使用）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 实验前导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.utils.data as tud\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据：使用hymenoptera_data数据集 \\\n",
    "数据集包括两类图片，bees和ants。这些数据都被处理成了可以使用ImageFolder来读取的格式。我们只需要把data_dir设置成数据的根目录，然后把model_name设置成我们想要使用的预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format\n",
    "data_dir = \"./hymenoptera_data\"\n",
    "model_name = \"resnet18\"\n",
    "num_class = 2\n",
    "#feature_extract = True\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读入数据: 把数据预处理成相应的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress\n",
    "all_imgs = datasets.ImageFolder(os.path.join(data_dir,\"train\"),\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.RandomResizedCrop(input_size),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),                                    \n",
    "                                ]))\n",
    "loader = tud.DataLoader(all_imgs,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7412, 0.7294, 0.7294,  ..., 0.6196, 0.6157, 0.6118],\n",
       "         [0.7490, 0.7412, 0.7333,  ..., 0.5882, 0.5922, 0.5961],\n",
       "         [0.7529, 0.7451, 0.7412,  ..., 0.5765, 0.5765, 0.5843],\n",
       "         ...,\n",
       "         [0.4471, 0.4627, 0.4549,  ..., 0.5333, 0.5569, 0.5529],\n",
       "         [0.4510, 0.4627, 0.4627,  ..., 0.5529, 0.5804, 0.5804],\n",
       "         [0.4824, 0.4824, 0.4824,  ..., 0.5608, 0.5843, 0.5608]],\n",
       "\n",
       "        [[0.6314, 0.6275, 0.6275,  ..., 0.4902, 0.4824, 0.4863],\n",
       "         [0.6392, 0.6353, 0.6314,  ..., 0.4667, 0.4667, 0.4667],\n",
       "         [0.6392, 0.6392, 0.6353,  ..., 0.4588, 0.4588, 0.4627],\n",
       "         ...,\n",
       "         [0.2784, 0.3255, 0.3373,  ..., 0.4196, 0.4431, 0.4078],\n",
       "         [0.3255, 0.3529, 0.3725,  ..., 0.4431, 0.4549, 0.4157],\n",
       "         [0.4000, 0.3961, 0.4039,  ..., 0.4392, 0.4196, 0.3647]],\n",
       "\n",
       "        [[0.5059, 0.4980, 0.5020,  ..., 0.3725, 0.3686, 0.3725],\n",
       "         [0.5137, 0.5098, 0.5059,  ..., 0.3529, 0.3490, 0.3569],\n",
       "         [0.5216, 0.5176, 0.5137,  ..., 0.3490, 0.3490, 0.3490],\n",
       "         ...,\n",
       "         [0.1882, 0.2314, 0.2392,  ..., 0.2941, 0.3216, 0.3020],\n",
       "         [0.2078, 0.2392, 0.2549,  ..., 0.3373, 0.3490, 0.3137],\n",
       "         [0.2784, 0.2824, 0.2980,  ..., 0.3490, 0.3373, 0.2784]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs[9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format\n",
    "batch_size = 32\n",
    "train_imgs = datasets.ImageFolder(os.path.join(data_dir,\"train\"),\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.RandomResizedCrop(input_size),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406],[0.229,0.224,0.225])\n",
    "                                ]))\n",
    "train_dataloader = tud.DataLoader(train_imgs,batch_size=batch_size,shuffle=True)\n",
    "test_imgs = datasets.ImageFolder(os.path.join(data_dir,\"val\"),\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.Resize(input_size),  \n",
    "                                    transforms.CenterCrop(input_size),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406],[0.229,0.224,0.225])\n",
    "                                ]))\n",
    "test_dataloader = tud.DataLoader(test_imgs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 配置网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Software\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\16040/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:14<00:00, 3.34MB/s]\n"
     ]
    }
   ],
   "source": [
    "# format\n",
    "def initialize_model(model_name,num_class,use_pretrained=True,feature_extract=True):\n",
    "    if model_name == \"resnet18\":\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        if feature_extract: # do not update the parameters\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_class)        \n",
    "    else:\n",
    "        print(\"model not implemented\")\n",
    "        return None\n",
    "    return model_ft\n",
    "model_ft = initialize_model(\"resnet18\",2,use_pretrained=True,feature_extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(model_ft.layer1[0].conv1.weight.requires_grad)\n",
    "print(model_ft.fc.weight.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "optimizer = optim.SGD(model_ft.parameters(),lr=lr,momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_dataloader,loss_fn,optimizer,epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    total_corrects = 0.\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        total_corrects += torch.sum(preds.eq(labels))\n",
    "    epoch_loss = total_loss / len(train_dataloader.dataset)\n",
    "    epoch_accuracy = total_corrects / len(train_dataloader.dataset)\n",
    "    print(\"Epoch:{}, Training Loss:{}, Traning Acc:{}\".format(epoch,epoch_loss,epoch_accuracy))  \n",
    "    #return model        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,test_dataloader,loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    total_corrects = 0.\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(test_dataloader):\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs,labels)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_corrects += torch.sum(preds.eq(labels))\n",
    "    epoch_loss = total_loss / len(test_dataloader.dataset)\n",
    "    epoch_accuracy = total_corrects / len(test_dataloader.dataset)\n",
    "    print(\"Test Loss:{}, Test Acc:{}\".format(epoch_loss,epoch_accuracy))  \n",
    "    return epoch_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Training Loss:0.6341719598066612, Traning Acc:0.6516393423080444\n",
      "Test Loss:0.3374541690147001, Test Acc:0.8692810535430908\n",
      "Epoch:1, Training Loss:0.40357414327683994, Traning Acc:0.8237704634666443\n",
      "Test Loss:0.23625953563677718, Test Acc:0.9477124214172363\n",
      "Epoch:2, Training Loss:0.33447326646476494, Traning Acc:0.8524590134620667\n",
      "Test Loss:0.21194470571536644, Test Acc:0.9411764740943909\n",
      "Epoch:3, Training Loss:0.24367607372706054, Traning Acc:0.9303278923034668\n",
      "Test Loss:0.23756680457420598, Test Acc:0.8954248428344727\n",
      "Epoch:4, Training Loss:0.24827324342532237, Traning Acc:0.9057376980781555\n",
      "Test Loss:0.21434232105616652, Test Acc:0.9281045794487\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "test_accuracy_hist = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model_ft,train_dataloader,loss_fn,optimizer,epoch)\n",
    "    acc = test_model(model_ft,test_dataloader,loss_fn)\n",
    "    test_accuracy_hist.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#torch.save(model.state_dict(),\"new_cnn.pth\")\n",
    "plt.title(\"Test Accuracy vs. Training Epoch\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),test_accuracy_hist,label=\"Pretrained\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1,num_epochs+1,1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拓展代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
